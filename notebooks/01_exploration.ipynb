{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n"
          ]
        }
      ],
      "source": [
        "# Import and reload the data loader module\n",
        "import importlib\n",
        "import src.data_loader as dl\n",
        "\n",
        "# Reload the module to get latest changes\n",
        "importlib.reload(dl)\n",
        "\n",
        "# Load the Titanic dataset (using correct path for project root)\n",
        "df = dl.load_df(\"data/raw/Titanic-Dataset.csv\")\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DATASET SUMMARY\n",
            "==================================================\n",
            "Shape: 891 rows Ã— 12 columns\n",
            "Memory usage: 0.31 MB\n",
            "\n",
            "MISSING VALUES:\n",
            "   Age: 177 (19.9%)\n",
            "   Cabin: 687 (77.1%)\n",
            "   Embarked: 2 (0.2%)\n",
            "\n",
            "DATA TYPES:\n",
            "   int64: 5 columns\n",
            "   object: 5 columns\n",
            "   float64: 2 columns\n",
            "\n",
            "NUMERIC COLUMNS:\n",
            "   PassengerId:\n",
            "      Mean: 446.00\n",
            "      Std: 257.35\n",
            "      Min: 1.00\n",
            "      Max: 891.00\n",
            "   Survived:\n",
            "      Mean: 0.38\n",
            "      Std: 0.49\n",
            "      Min: 0.00\n",
            "      Max: 1.00\n",
            "   Pclass:\n",
            "      Mean: 2.31\n",
            "      Std: 0.84\n",
            "      Min: 1.00\n",
            "      Max: 3.00\n",
            "   Age:\n",
            "      Mean: 29.70\n",
            "      Std: 14.53\n",
            "      Min: 0.42\n",
            "      Max: 80.00\n",
            "   SibSp:\n",
            "      Mean: 0.52\n",
            "      Std: 1.10\n",
            "      Min: 0.00\n",
            "      Max: 8.00\n",
            "   Parch:\n",
            "      Mean: 0.38\n",
            "      Std: 0.81\n",
            "      Min: 0.00\n",
            "      Max: 6.00\n",
            "   Fare:\n",
            "      Mean: 32.20\n",
            "      Std: 49.69\n",
            "      Min: 0.00\n",
            "      Max: 512.33\n",
            "\n",
            "CATEGORICAL COLUMNS:\n",
            "   Name: 891 unique values, most common: 'Dooley, Mr. Patrick'\n",
            "   Sex: 2 unique values, most common: 'male'\n",
            "   Ticket: 681 unique values, most common: '347082'\n",
            "   Cabin: 147 unique values, most common: 'G6'\n",
            "   Embarked: 3 unique values, most common: 'S'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# summarize data\n",
        "summary = dl.summarize_df(df)\n",
        "print(summary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing embedding generator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:src.embeddings:Loading embedding model: all-MiniLM-L6-v2\n",
            "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
            "INFO:src.embeddings:Model loaded successfully. Embedding dimension: 384\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "587f8736214e468698056af8511060cf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:src.embeddings:Generating embeddings for 3 texts...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Single embedding shape: (384,)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "334232c05fa240a787a0e4965c5caae6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:src.embeddings:Generated 3 embeddings with dimension 384\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch embeddings shape: (3, 384)\n",
            "Similarity between first two embeddings: 0.8852\n"
          ]
        }
      ],
      "source": [
        "# Test the embedding generator\n",
        "import src.embeddings as embeddings\n",
        "importlib.reload(embeddings)\n",
        "\n",
        "generator = embeddings.EmbeddingGenerator()\n",
        "\n",
        "# Test single embedding\n",
        "test_text = \"This is a test sentence for embedding generation.\"\n",
        "embedding = generator.generate_embedding(test_text)\n",
        "print(f\"Single embedding shape: {embedding.shape}\")\n",
        "\n",
        "# Test batch embeddings\n",
        "test_texts = [\n",
        "    \"First test sentence\",\n",
        "    \"Second test sentence\", \n",
        "    \"Third test sentence\"\n",
        "]\n",
        "batch_embeddings = generator.generate_embeddings_batch(test_texts)\n",
        "print(f\"Batch embeddings shape: {batch_embeddings.shape}\")\n",
        "\n",
        "# Test similarity\n",
        "sim = generator.similarity(batch_embeddings[0], batch_embeddings[1])\n",
        "print(f\"Similarity between first two embeddings: {sim:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing vector store and similarity search\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:src.vector_store:Created FAISS IndexFlatL2\n",
            "INFO:src.vector_store:VectorStore initialized with 384D vectors, flat index, json mapping\n",
            "INFO:src.vector_store:Added 5 vectors to index. Total vectors: 5\n",
            "INFO:src.vector_store:Found 3 similar vectors\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added vectors with IDs: [0, 1, 2, 3, 4]\n",
            "Query vector shape: (384,)\n",
            "\n",
            "Search results:\n",
            "ID: 3, Distance: 62.7210, Similarity: 0.0157, Metadata: {'text': 'Fourth document', 'category': 'C'}\n",
            "ID: 4, Distance: 63.2829, Similarity: 0.0156, Metadata: {'text': 'Fifth document', 'category': 'B'}\n",
            "ID: 1, Distance: 63.9098, Similarity: 0.0154, Metadata: {'text': 'Second document', 'category': 'B'}\n",
            "\n",
            "Store stats: {'vector_count': 5, 'dimension': 384, 'index_type': 'flat', 'mapping_type': 'json', 'is_trained': True}\n"
          ]
        }
      ],
      "source": [
        "# Test the vector store\n",
        "import src.vector_store as vs\n",
        "import numpy as np\n",
        "\n",
        "dimension = 384  # all-MiniLM-L6-v2 dimension\n",
        "\n",
        "# Create vector store\n",
        "store = vs.VectorStore(dimension=dimension, index_type=\"flat\", mapping_type=\"json\")\n",
        "\n",
        "# Create some test vectors\n",
        "test_vectors = np.random.rand(5, dimension).astype('float32')\n",
        "test_metadata = [\n",
        "    {\"text\": \"First document\", \"category\": \"A\"},\n",
        "    {\"text\": \"Second document\", \"category\": \"B\"},\n",
        "    {\"text\": \"Third document\", \"category\": \"A\"},\n",
        "    {\"text\": \"Fourth document\", \"category\": \"C\"},\n",
        "    {\"text\": \"Fifth document\", \"category\": \"B\"}\n",
        "]\n",
        "\n",
        "# Add vectors\n",
        "vector_ids = store.add_vectors(test_vectors, test_metadata)\n",
        "print(f\"Added vectors with IDs: {vector_ids}\")\n",
        "\n",
        "# Search for similar vectors\n",
        "query = test_vectors[0]  # Use first vector as query\n",
        "results = store.search(query, k=3)\n",
        "\n",
        "print(\"\\nSearch results:\")\n",
        "for result in results:\n",
        "    print(f\"ID: {result['id']}, Distance: {result['distance']:.4f}, \"\n",
        "            f\"Similarity: {result['similarity']:.4f}, Metadata: {result['metadata']}\")\n",
        "\n",
        "# Get stats\n",
        "stats = store.get_stats()\n",
        "print(f\"\\nStore stats: {stats}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
